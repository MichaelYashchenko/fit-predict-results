{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bf59007c",
   "metadata": {
    "cellId": "bffguzf03he1zpcnwwdya4"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel\n",
    "from transformers.models.bert.tokenization_bert import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "56c412c0",
   "metadata": {
    "cellId": "on5f4prvgf8emxpeek4z2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "MAX_LENGTH = 50\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "472dab56",
   "metadata": {
    "cellId": "zh35cuonfs962wh3xte4ls"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def fix_seed(seed: int = 42) -> None:\n",
    "    \"\"\"\n",
    "    Set seeds for reproducibility\n",
    "    :param seed: seed value\n",
    "    \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "975ef207",
   "metadata": {
    "cellId": "f8rkje9k687dgs082rgke"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-d93244555785>:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_use_df['sentence'] = train_use_df['sentence'].apply(lambda x: only_char_left(x))\n",
      "<ipython-input-67-d93244555785>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_use_df['sentence'] = train_use_df['sentence'].apply(lambda x: ' '.join(x.lower().split(' ')))\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "fix_seed(42)\n",
    "\n",
    "model_cache_path = Path('./model_cache')\n",
    "model_cache_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_model_name = \"cointegrated/rubert-tiny\"\n",
    "\n",
    "trained_model_path = Path('./trained_model_artifacts')\n",
    "trained_model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, test_losses, train_accuracies, test_accuracies):\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n",
    "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label='train')\n",
    "    axs[0].plot(range(1, len(test_losses) + 1), test_losses, label='test')\n",
    "    axs[0].set_ylabel('loss')\n",
    "\n",
    "    axs[1].plot(range(1, len(train_accuracies) + 1), train_accuracies, label='train')\n",
    "    axs[1].plot(range(1, len(test_accuracies) + 1), test_accuracies, label='test')\n",
    "    axs[1].set_ylabel('metric')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "os.listdir('.')\n",
    "os.listdir('../../mnt/s3/hsedatafitpredict1392')\n",
    "train_df = pd.read_parquet('../../mnt/s3/hsedatafitpredict1392/mega_train.parquet')\n",
    "\n",
    "train_use_df = train_df[['sentence', 'communication', 'price', 'quality', 'safety']]\n",
    "train_use_df[['communication', 'price', 'quality', 'safety']]\n",
    "\n",
    "def only_char_left(text):\n",
    "    text_new = ''\n",
    "    for i in text:\n",
    "        if i.isalpha() or i == ' ':\n",
    "            text_new += i\n",
    "    return text_new\n",
    "        \n",
    "    \n",
    "train_use_df['sentence'] = train_use_df['sentence'].apply(lambda x: only_char_left(x))\n",
    "train_use_df['sentence'] = train_use_df['sentence'].apply(lambda x: ' '.join(x.lower().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39cc24cb",
   "metadata": {
    "cellId": "oz4zzw0ubim3n087xik1bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-86420291f26a>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_use_df['temp'] = train_use_df['communication'] + train_use_df['price'] + train_use_df['quality'] + train_use_df['safety']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_use_df['temp'] = train_use_df['communication'] + train_use_df['price'] + train_use_df['quality'] + train_use_df['safety']\n",
    "train_use_df = train_use_df[train_use_df.temp != 0]\n",
    "train_use_df = train_use_df[['sentence', 'communication', 'price', 'quality', 'safety']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d08e46bf",
   "metadata": {
    "cellId": "en3xex11nwpu10au25snpp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_use_df.loc[:, 'communication'] = (~(train_use_df.loc[:, 'communication'] == 0.0)).astype(int)\n",
    "train_use_df.loc[:, 'price'] = (~(train_use_df.loc[:, 'price'] == 0.0)).astype(int)\n",
    "train_use_df.loc[:, 'quality'] = (~(train_use_df.loc[:, 'quality'] == 0.0)).astype(int)\n",
    "train_use_df.loc[:, 'safety'] = (~(train_use_df.loc[:, 'safety'] == 0.0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efa0defc",
   "metadata": {
    "cellId": "3nsnquma83moco0jc1q5l"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>communication</th>\n",
       "      <th>price</th>\n",
       "      <th>quality</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хотелось бы выразить огромную благодарность...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>на что сотрудник банка ответила мне что данну...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>тем самым оставив меня без средств к существо...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>заблокировали счет якобы изза просроченой зад...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>в итоге даже не извинилисьдолго искали картуот...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>я просто в шоке ничего о том что сосчет можно ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>я просто не в состоянии заплатить такую сумму ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>я у сотрудника спросила получила ответ но сотр...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>восхищаюсь я проходит еще неделя ну я думаю и...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>вы своих клиентов совсем не уважаете считая их...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6287 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  ...  safety\n",
       "0        хотелось бы выразить огромную благодарность...  ...       0\n",
       "1      на что сотрудник банка ответила мне что данну...  ...       0\n",
       "2      тем самым оставив меня без средств к существо...  ...       0\n",
       "4      заблокировали счет якобы изза просроченой зад...  ...       0\n",
       "5     в итоге даже не извинилисьдолго искали картуот...  ...       0\n",
       "...                                                 ...  ...     ...\n",
       "7159  я просто в шоке ничего о том что сосчет можно ...  ...       1\n",
       "7160  я просто не в состоянии заплатить такую сумму ...  ...       0\n",
       "7162  я у сотрудника спросила получила ответ но сотр...  ...       1\n",
       "7163   восхищаюсь я проходит еще неделя ну я думаю и...  ...       0\n",
       "7164  вы своих клиентов совсем не уважаете считая их...  ...       0\n",
       "\n",
       "[6287 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_use_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7c030c8a",
   "metadata": {
    "cellId": "x8n5hy4jukht026or8q67"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tr, valid = train_test_split(train_use_df, random_state=101, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "cf9b1e49",
   "metadata": {
    "cellId": "dnnj38219pq5d992qmeold"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>communication</th>\n",
       "      <th>price</th>\n",
       "      <th>quality</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>даже не хочется думать какие препоны нас ждут ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>звонить бесполезно хоть на  час хоть на  часов</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>менеджер бойко отвечает в банкоматах райффайзе...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>видно что есть определенные стандарты работы и...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>последнее обращение составлено  октября  до си...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  ...  safety\n",
       "1478  даже не хочется думать какие препоны нас ждут ...  ...     0.0\n",
       "1922     звонить бесполезно хоть на  час хоть на  часов  ...     0.0\n",
       "2601  менеджер бойко отвечает в банкоматах райффайзе...  ...     0.0\n",
       "972   видно что есть определенные стандарты работы и...  ...     0.0\n",
       "4512  последнее обращение составлено  октября  до си...  ...     0.0\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bad2cb18",
   "metadata": {
    "cellId": "1nmmzrnmrfsjs6uewvn8ozi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence         даже не хочется думать какие препоны нас ждут ...\n",
       "communication                                                 6906\n",
       "price                                                          435\n",
       "quality                                                       5350\n",
       "safety                                                         259\n",
       "dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "tr.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "50f2d6f3",
   "metadata": {
    "cellId": "t05teqd2ovlo93vpq755cm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tr_price = tr[(tr.price == 1) ] # & (tr.communication == 0) & (tr.quality == 0)\n",
    "tr_safety = tr[(tr.safety == 1) ]  # & (tr.communication == 0) & (tr.quality == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3b7527f8",
   "metadata": {
    "cellId": "4sylsc14vn6o5vyopflqy"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tr_ups = tr.copy()\n",
    "for i in range(10):\n",
    "    tr_ups = pd.concat([tr_ups, tr_price, tr_safety], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4f5e16fc",
   "metadata": {
    "cellId": "uwt0h3bp5wmgtnmo1wd7po"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for i in range(4):\n",
    "    tr_ups = pd.concat([tr_ups, tr_safety], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f630e5f9",
   "metadata": {
    "cellId": "87xs1iiu0s8d5klz9n8vvu"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for i in range(2):\n",
    "    tr_ups = pd.concat([tr_ups, tr_safety], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a76edd8f",
   "metadata": {
    "cellId": "gb9dmwdpotnyn3wcuzxtu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence         даже не хочется думать какие препоны нас ждут ...\n",
       "communication                                                10020\n",
       "price                                                         2261\n",
       "quality                                                       8444\n",
       "safety                                                        2403\n",
       "dtype: object"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# print(tr.shape)\n",
    "tr_ups.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6c906ca5",
   "metadata": {
    "cellId": "129weltx40kkwvmquqgcm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['communication', 'price', 'quality', 'safety']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "labels = train_use_df.columns[1:].tolist()\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d58e1171",
   "metadata": {
    "cellId": "bws2h459t3dtn53gemrj1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'communication', 1: 'price', 2: 'quality', 3: 'safety'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8a555e77",
   "metadata": {
    "cellId": "aiqit6uk4dwzyy8uw021l"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# tr.loc[:, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1765a9f1",
   "metadata": {
    "cellId": "eu07e5sqludvkacmh64l7n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.targets = df.loc[:, labels].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.df.iloc[index, 0]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4d9dc685",
   "metadata": {
    "cellId": "en9et83ia7u266d7ze9lpr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "base_rubert = BertModel.from_pretrained(base_model_name, cache_dir = model_cache_path)\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(base_model_name, cache_dir = model_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "79ac8d4d",
   "metadata": {
    "cellId": "a0vs3l7cm7qbth2vmw7rq"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BERTDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-d45bb123ce1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_ups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BERTDataset' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_dataset = BERTDataset(tr_ups, tokenizer, MAX_LENGTH)\n",
    "valid_dataset = BERTDataset(valid, tokenizer, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ca187a65",
   "metadata": {
    "cellId": "sgik3xwpqpcbi1b5yi0oz"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-92681a704c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_loader = DataLoader(train_dataset, batch_size=256, \n\u001b[0m\u001b[1;32m      2\u001b[0m                           shuffle=True)\n\u001b[1;32m      3\u001b[0m valid_loader = DataLoader(valid_dataset, batch_size=64, \n\u001b[1;32m      4\u001b[0m                           shuffle=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, \n",
    "                          shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, \n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d235b24e",
   "metadata": {
    "cellId": "lbxo0arsci8r3d66hqv8lo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class CategoriesBERT(nn.Module):\n",
    "    def __init__(self, \n",
    "                 base_model: BertModel,\n",
    "                 dropout: float = 0.3,\n",
    "                 last_embedding_dim: int = 312, \n",
    "                 classification_dim: int = 4):\n",
    "        \n",
    "        super(CategoriesBERT, self).__init__()\n",
    "        \n",
    "        self.bert_model = base_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(last_embedding_dim, classification_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):        \n",
    "        _, pooled_output = self.bert_model(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "        \n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        \n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0c4d4b99",
   "metadata": {
    "cellId": "6hzhmcfcr94733rs5zdo3"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f43778ff",
   "metadata": {
    "cellId": "zsl6q4sf0f2crpjtbcjd8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.cuda.current_device()\n",
    "model = CategoriesBERT(base_model=base_rubert)\n",
    "model.to(device)\n",
    "optimizer = AdamW(params = model.parameters(), lr=0.00001, weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ddbbc3ce",
   "metadata": {
    "cellId": "m9bo8w6xmnqfzul9d2x4n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "best_metric = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "bfba07df",
   "metadata": {
    "cellId": "fhu1256h3cgvhfiu4yjc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    if epoch % 20 == 0:\n",
    "        print('________________')\n",
    "        print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        outputs, targets = validation()\n",
    "        ans = np.array(outputs) >= 0.5\n",
    "        accuracy = metrics.accuracy_score(targets, ans)\n",
    "        f1_score_micro = metrics.f1_score(targets, ans, average='micro')\n",
    "        f1_score_macro = metrics.f1_score(targets, ans, average='macro')\n",
    "        roc_auc = metrics.roc_auc_score(targets, outputs, average='weighted', multi_class='ovr')\n",
    "        print(f\"Accuracy Score = {accuracy}\")\n",
    "        print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "        print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
    "        print(f\"Roc AUC (Macro) = {roc_auc}\")\n",
    "\n",
    "        if roc_auc > best_metric:\n",
    "            torch.save(model.state_dict(), 'multi_label_model.bin')\n",
    "    else:\n",
    "        print('________________')\n",
    "        print(f'Epoch: {epoch}, Loss:  {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5af2d787",
   "metadata": {
    "cellId": "sa6q159tn6jg1rxxgso1q"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def validation():\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(valid_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "497a17ea",
   "metadata": {
    "cellId": "xmzjvx0j20pouduw665z3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________\n",
      "Epoch: 0, Loss:  0.7342463135719299\n",
      "Accuracy Score = 0.0\n",
      "F1 Score (Micro) = 0.5090370370370371\n",
      "F1 Score (Macro) = 0.4293079418728047\n",
      "Roc AUC (Macro) = 0.5426747860197787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-769ab6f6690e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-2452a5893c4f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-abc03e478f7b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         inputs = self.tokenizer.encode_plus(\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2501\u001b[0m         )\n\u001b[1;32m   2502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2504\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m             )\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                 \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;31m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_accents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_split_on_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhitespace_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_run_split_on_punc\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mstart_new_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_is_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1c6f2",
   "metadata": {
    "cellId": "6mzlfoix92xxyiykoztl5",
    "execution_id": "f0601a8d-32d5-40e7-94af-17abdea938f8"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5803636e",
   "metadata": {
    "cellId": "3l062sqm3vj5iyqhh7i0sr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_df = pd.read_csv('../../mnt/s3/hsedatafitpredict1392/new_test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "deeef045",
   "metadata": {
    "cellId": "pshpeg81p5os4ya1jwo2o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model = CategoriesBERT(base_model=base_rubert)\n",
    "model.load_state_dict(torch.load('multi_label_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "469a809d",
   "metadata": {
    "cellId": "g1jp8vsu7wc4kk6w0p1pm4"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for lab in labels:\n",
    "    test_df.loc[:, lab] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ccbf9978",
   "metadata": {
    "cellId": "ojtk2yrg84fxtjhspq4ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b098aefd",
   "metadata": {
    "cellId": "jvt6zfow4590qpmqmi2h3hi"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for i in range(len(test_df)):\n",
    "    model.eval().cpu()\n",
    "    text = test_df.iloc[i, 0]\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        ids = torch.tensor(inputs['input_ids'], dtype=torch.long).unsqueeze(0)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).unsqueeze(0)\n",
    "        token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0)\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        outputs = 1/(1 + np.exp(-outputs.numpy()[0]))\n",
    "    \n",
    "    test_df.iloc[i, 1:] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "df802b5e",
   "metadata": {
    "cellId": "tgfruexg2yxbycij3b2qd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'communication', 1: 'price', 2: 'quality', 3: 'safety'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d762a573",
   "metadata": {
    "cellId": "54ah66gh56ov6c5p3rxc4p"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-73c129342cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "outputs.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7a5f760c",
   "metadata": {
    "cellId": "4n90it6b1kgdm3gan107"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_sent_df = pd.read_csv('../../mnt/s3/hsedatafitpredict1392/test_answer/fit_predict_bert_sent.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d1baaeae",
   "metadata": {
    "cellId": "vjmgkiqhsu192c0z5ku86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>?</th>\n",
       "      <th>-</th>\n",
       "      <th>+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>15.03.2022 обратился на горячую линию для закр...</td>\n",
       "      <td>0.568540</td>\n",
       "      <td>0.321740</td>\n",
       "      <td>0.109720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>Уже который год в ТКБ не решается \"глобальная ...</td>\n",
       "      <td>0.192277</td>\n",
       "      <td>0.475214</td>\n",
       "      <td>0.332509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>Добрый день. Хочу оставить отзыв о пользовании...</td>\n",
       "      <td>0.537145</td>\n",
       "      <td>0.203312</td>\n",
       "      <td>0.259543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>Добрый день Сегодня, зайдя в свой личный кабин...</td>\n",
       "      <td>0.373189</td>\n",
       "      <td>0.205419</td>\n",
       "      <td>0.421392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>Обслуживаюсь в Тинькофф пару лет, возникла жес...</td>\n",
       "      <td>0.420800</td>\n",
       "      <td>0.176457</td>\n",
       "      <td>0.402744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Отвратительный сервис и отношение к клиентам! ...</td>\n",
       "      <td>0.147801</td>\n",
       "      <td>0.170057</td>\n",
       "      <td>0.682142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>28.04.2022 обратилась в банк о возможности пер...</td>\n",
       "      <td>0.762713</td>\n",
       "      <td>0.097972</td>\n",
       "      <td>0.139315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>В начале 2021 года была акция по выплате 8% ке...</td>\n",
       "      <td>0.614543</td>\n",
       "      <td>0.185364</td>\n",
       "      <td>0.200093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>Бездействие банка и некомпетентность сотрудник...</td>\n",
       "      <td>0.340911</td>\n",
       "      <td>0.241325</td>\n",
       "      <td>0.417763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Потрачено 5 часов чтобы произвести оплату за о...</td>\n",
       "      <td>0.307848</td>\n",
       "      <td>0.437166</td>\n",
       "      <td>0.254985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts  ...         +\n",
       "4036  15.03.2022 обратился на горячую линию для закр...  ...  0.109720\n",
       "5804  Уже который год в ТКБ не решается \"глобальная ...  ...  0.332509\n",
       "2752  Добрый день. Хочу оставить отзыв о пользовании...  ...  0.259543\n",
       "1921  Добрый день Сегодня, зайдя в свой личный кабин...  ...  0.421392\n",
       "7374  Обслуживаюсь в Тинькофф пару лет, возникла жес...  ...  0.402744\n",
       "...                                                 ...  ...       ...\n",
       "146   Отвратительный сервис и отношение к клиентам! ...  ...  0.682142\n",
       "2677  28.04.2022 обратилась в банк о возможности пер...  ...  0.139315\n",
       "4481  В начале 2021 года была акция по выплате 8% ке...  ...  0.200093\n",
       "4112  Бездействие банка и некомпетентность сотрудник...  ...  0.417763\n",
       "943   Потрачено 5 часов чтобы произвести оплату за о...  ...  0.254985\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "test_sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "36a4ef1d",
   "metadata": {
    "cellId": "j615wjubv2hepn6hk43cd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "total_answer = pd.merge(left=test_sent_df, right=test_df, right_index=True, left_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "028aed5b",
   "metadata": {
    "cellId": "n36a7lfofqfser44svc26"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "total_answer = total_answer[['texts_x', '?', '-', '+', 'communication', 'price', 'quality','safety']]\n",
    "total_answer.columns = ['texts', '?', '-', '+', 'communication', 'price', 'quality','safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "915268be",
   "metadata": {
    "cellId": "usymua43kxictwxlwpc9o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Здравствуйте !!! Сегодня, мне позвонили, из Московского Коммерческого Банка, с телефона, +79*****1124, с предложением, потребительского кредита и не дослушав, мой ответ, БРОСИЛИ ТРУБКУ !!! Я конечно, всё понимаю, но с таким отношением, к...'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "idx = 555\n",
    "total_answer.iloc[idx].texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6de8c58b",
   "metadata": {
    "cellId": "vqackyzwuvfzsg4ltnyduc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "total_answer.loc[:, 'second_category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "49e21ad5",
   "metadata": {
    "cellId": "5v1no3eawl66ealurecja8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "total_answer.loc[:, 'second_category'] = np.where((total_answer[['communication', 'price', \n",
    "                                                                'quality','safety']] > 0.5).sum(axis=1) >= 2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9017cb28",
   "metadata": {
    "cellId": "6x1y4dty47gp3miz9xl0j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "texts              После введенных ЦБ ограничений выдача наличных...\n",
       "?                                                           0.395454\n",
       "-                                                              0.484\n",
       "+                                                           0.120546\n",
       "communication                                               0.504164\n",
       "price                                                       0.601446\n",
       "quality                                                     0.637835\n",
       "safety                                                           0.5\n",
       "second_category                                                    1\n",
       "Name: 3925, dtype: object"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "total_answer.loc[3925]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d41a79d3",
   "metadata": {
    "cellId": "m9aupmo2avrv91rc2j7js"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>?</th>\n",
       "      <th>-</th>\n",
       "      <th>+</th>\n",
       "      <th>communication</th>\n",
       "      <th>price</th>\n",
       "      <th>quality</th>\n",
       "      <th>safety</th>\n",
       "      <th>second_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>После введенных ЦБ ограничений выдача наличных...</td>\n",
       "      <td>0.395454</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.120546</td>\n",
       "      <td>0.504164</td>\n",
       "      <td>0.601446</td>\n",
       "      <td>0.637835</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>02.08.2021 я передал в ПАО Сбербанк заявление ...</td>\n",
       "      <td>0.611788</td>\n",
       "      <td>0.263567</td>\n",
       "      <td>0.124645</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.658181</td>\n",
       "      <td>0.623527</td>\n",
       "      <td>0.538851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>Взял потребительский кредит в Совкомбанке, за ...</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.476742</td>\n",
       "      <td>0.130359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.606375</td>\n",
       "      <td>0.577957</td>\n",
       "      <td>0.581178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>14.02.2022г на счет моей матери 408179********...</td>\n",
       "      <td>0.283775</td>\n",
       "      <td>0.485782</td>\n",
       "      <td>0.230443</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.701118</td>\n",
       "      <td>0.563654</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>Пытаюсь продлить страховой полис. На сайте нет...</td>\n",
       "      <td>0.091968</td>\n",
       "      <td>0.848435</td>\n",
       "      <td>0.059596</td>\n",
       "      <td>0.507730</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563039</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>11 .03 обратилась в коллцентр банка с заявкой ...</td>\n",
       "      <td>0.440657</td>\n",
       "      <td>0.492002</td>\n",
       "      <td>0.067342</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.562620</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.522822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>9 октября 2022г., я снимала деньги с карты Газ...</td>\n",
       "      <td>0.155579</td>\n",
       "      <td>0.738466</td>\n",
       "      <td>0.105955</td>\n",
       "      <td>0.564595</td>\n",
       "      <td>0.614716</td>\n",
       "      <td>0.664643</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>Как развидеть и раслышать банк? Более двух лет...</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>0.867250</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>Хочу поблагодарить службу поддержки Газпромбан...</td>\n",
       "      <td>0.171670</td>\n",
       "      <td>0.162058</td>\n",
       "      <td>0.666273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.560088</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>Решила оформить курсы в рассрочку. Европа банк...</td>\n",
       "      <td>0.330430</td>\n",
       "      <td>0.251698</td>\n",
       "      <td>0.417872</td>\n",
       "      <td>0.509026</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.509042</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts  ...  second_category\n",
       "3925  После введенных ЦБ ограничений выдача наличных...  ...                0\n",
       "7492  02.08.2021 я передал в ПАО Сбербанк заявление ...  ...                0\n",
       "6856  Взял потребительский кредит в Совкомбанке, за ...  ...                0\n",
       "4506  14.02.2022г на счет моей матери 408179********...  ...                0\n",
       "6511  Пытаюсь продлить страховой полис. На сайте нет...  ...                0\n",
       "...                                                 ...  ...              ...\n",
       "4196  11 .03 обратилась в коллцентр банка с заявкой ...  ...                0\n",
       "115   9 октября 2022г., я снимала деньги с карты Газ...  ...                0\n",
       "5122  Как развидеть и раслышать банк? Более двух лет...  ...                0\n",
       "3922  Хочу поблагодарить службу поддержки Газпромбан...  ...                0\n",
       "5217  Решила оформить курсы в рассрочку. Европа банк...  ...                0\n",
       "\n",
       "[126 rows x 9 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "total_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "dc8facb1",
   "metadata": {
    "cellId": "eis0hznm4dvmvfc2v4r4g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "texts              15.03.2022 обратился на горячую линию для закр...\n",
       "?                                                            0.56854\n",
       "-                                                            0.32174\n",
       "+                                                            0.10972\n",
       "communication                                                    0.5\n",
       "price                                                            0.5\n",
       "quality                                                     0.501729\n",
       "safety                                                           0.5\n",
       "second_category                                                    0\n",
       "Name: 4036, dtype: object"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "total_answer.loc[4036]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4ede5b70",
   "metadata": {
    "cellId": "grx6x9g61jba8k9olcauor"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "total_answer.to_csv('../../mnt/s3/hsedatafitpredict1392/test_answer/fit_predict_total_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19c487",
   "metadata": {
    "cellId": "ykl3rkphe5hg6qgpcjaii"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "e63a6a95-351b-43ec-a52b-6a629e34ba6f",
  "notebookPath": "Untitled1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
